{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4b2e41-d0b4-4d37-bc7d-85c2a6dbeb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from pptx import Presentation\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.util import Cm, Pt, Inches\n",
    "from pptx.enum.text import MSO_ANCHOR, MSO_AUTO_SIZE\n",
    "from h2ogpte import H2OGPTE\n",
    "from mediawikiapi import MediaWikiAPI\n",
    "from tqdm import tqdm\n",
    "with open('secrets.txt') as f:\n",
    "    api = f.read()\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2c9a1b-6481-447e-9513-732dc1e44eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = H2OGPTE(\n",
    "    address=\"https://h2ogpte.genai.h2o.ai\",\n",
    "    api_key=api\n",
    ")\n",
    "\n",
    "user_query = 'Create a presentation on barbie and oppenheimer (barbenheimer)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c753be01-40dc-4a03-8d7a-5af7397ccdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(lst, retain=30):\n",
    "    '''\n",
    "    Trims a list. This function was originally used to permute before trimming, but\\\n",
    "    now that functionality is removed, so it appears rather redundant.\n",
    "    '''\n",
    "    _ = lst.copy()\n",
    "    \n",
    "    return _[0:retain]\n",
    "\n",
    "\n",
    "\n",
    "def try_and_parse(user_query, function, failed=0, markdown=False):\n",
    "    '''\n",
    "    Accepts a function and user_query, an input. Evaluates function(user_query) and \n",
    "    converts string output (usually a reply from an llm) into a json value. Use markdown=True\n",
    "    if the json value is contained within a code chunk.\n",
    "    '''\n",
    "    chosen = function(user_query)\n",
    "    try:\n",
    "        if not markdown:\n",
    "            topics = json.loads(chosen.content)\n",
    "        else:\n",
    "            print(chosen.content)\n",
    "            pattern = r'^```(?:\\w+)?\\s*\\n(.*?)(?=^```)```'\n",
    "            result = re.findall(pattern, chosen.content, re.DOTALL | re.MULTILINE)[0].strip() \n",
    "            #print(result)\n",
    "            topics = json.loads(result)\n",
    "            \n",
    "        return topics\n",
    "    except Exception as e:\n",
    "        failed+=1\n",
    "        print(failed)\n",
    "        print(e)# CHANGE TO LOGGING STATEMENT\n",
    "        try_and_parse(user_query, function, failed=failed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d0758-d9ad-48ba-9b95-555f5e0001bb",
   "metadata": {},
   "source": [
    "## Step 1. What comes to mind when you think about xyz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0070654e-5a34-45a9-a233-d924424311c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Barbie',\n",
       " 'Oppenheimer',\n",
       " 'Barbie and Oppenheimer in popular culture',\n",
       " 'Barbie (doll)',\n",
       " 'J. Robert Oppenheimer']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = lambda user_query: client.answer_question(\n",
    "    question=user_query,\n",
    "    system_prompt=\"\"\"You are an assistant whose task is to perform Wikipedia searches on a specific topic.\\\n",
    "    The user is interested to create a presentation about a topic of interest.\\\n",
    "    Reply with at least one corresponding Wikipedia query as an array in JSON format.\\\n",
    "    Only reply with the JSON array and nothing else. Here are some examples.\n",
    "    Example 1.\n",
    "    User: Create a presentation on the book, Baby Rudin.\n",
    "    Assistant: [\"Real analysis\", \"Mathematical Analysis\"]\n",
    "\n",
    "    Example 2.\n",
    "    User: I want to create a ppt about Milk.\n",
    "    Assistant: [\"Milk\", \"Plant Milk\", \"Animal Milk\", \"Almond Milk\"]\n",
    "    \"\"\",\n",
    "    llm='mistralai/Mixtral-8x7B-Instruct-v0.1' # i like this model\n",
    ")\n",
    "searched = try_and_parse(user_query, search)\n",
    "searched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991985cf-7860-4389-bb76-ae2b1e65c255",
   "metadata": {},
   "source": [
    "## Step 2. Search Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9774e298-43a4-410d-8ca5-cab51af71220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "wiki = MediaWikiAPI()\n",
    "\n",
    "articles = list(\n",
    "    set(\n",
    "        \n",
    "        [i for j in [wiki.search(cat, results=5) for cat in searched] for i in j]\n",
    "        \n",
    "    )\n",
    ") # remove duplicates with set(list())\n",
    "random.shuffle(articles) # random shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc504cd6-6449-47e4-87cf-45d4385c39e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Kenneth Sean \"Ken\" Carson Jr.\n",
      "\n",
      "1. Margaret \"Midge\" Hadley Sherwood is a doll character in the Barbie line of toys by Mattel that was first released in 1963.\n",
      "\n",
      "2. Barbie is a fashion doll created by American businesswoman Ruth Handler, manufactured by American toy and entertainment company Mattel and introduced on March 9, 1959.\n",
      "\n",
      "3. Nikolaus Barbie (25 October 1913 – 25 September 1991) was a German officer of the SS and SD who worked in Vichy France during World War II. He became known as the \"Butcher of Lyon\" for having personally tortured prisoners—primarily Jews and members of the French Resistance—as the head of the Gestapo in Lyon.\n",
      "\n",
      "4. Go woke, go broke, or alternatively get woke, go broke, is an American political catchphrase used by some political pundits to refer to the actual or perceived stock value drops or loss in sales (\"going broke\") of companies or corporations that publicly support progressive causes, such as the treatment of women, LGBT people and people of color (termed as \"going woke\" by its opponents).\n",
      "\n",
      "5. The Oppenheimer security hearing, conducted by the United States Atomic Energy Commission (AEC) over four weeks in 1954, explored the background, actions, and associations of J. Robert Oppenheimer, the American scientist who directed the Los Alamos Laboratory during World War II as part of the Manhattan Project to develop the atomic bomb.\n",
      "\n",
      "6. American Prometheus: The Triumph and Tragedy of J. Robert Oppenheimer is a 2005 biography of theoretical physicist J. Robert Oppenheimer, the leader of the Manhattan Project which produced the first nuclear weapons, written by Kai Bird and Martin J. Sherwin over a period of 25 years.\n",
      "\n",
      "7. Frank Friedman Oppenheimer (14 August 1912 – 3 February 1985) was an American particle physicist, cattle rancher, professor of physics at the University of Colorado, and the founder of the Exploratorium in San Francisco.\n",
      "\n",
      "8. Barbie is a 2023 fantasy comedy film, directed by Greta Gerwig from a screenplay she wrote with Noah Baumbach.\n",
      "\n",
      "9. Since 2001, Barbie, a fashion doll manufactured by American toy and entertainment company Mattel, has starred or featured in 42 CGI or computer-animated feature films and streaming television films which since then has become a core component of an eponymous media franchise.\n",
      "\n",
      "10. Barbenheimer ( BAR-bən-hy-mər) is a cultural phenomenon which preceded and continues to surround the simultaneous theatrical release of two films, Warner Bros.\n",
      "\n",
      "11. Rustin is a 2023 American biographical drama film directed by George C. Wolfe, from a screenplay by Julian Breece and Dustin Lance Black, and a story by Breece about the life of civil rights activist Bayard Rustin.\n",
      "\n",
      "12. Oppenheimer is a 2023 epic biographical thriller film written, directed, and co-produced by Christopher Nolan, starring Cillian Murphy as J. Robert Oppenheimer, the American theoretical physicist credited with being the \"father of the atomic bomb\" for his role in the Manhattan Project—the World War II undertaking that developed the first nuclear weapons.\n",
      "\n",
      "13. The 49th ceremony of the People's Choice Awards was held on February 18, 2024, at the Barker Hangar in Santa Monica, California.\n",
      "\n",
      "14. This article shows the complete fictional and non-fictional friends and family of Barbie, a fashion doll manufactured by American toy and entertainment company Mattel and launched on 9 March 1959.\n",
      "\n",
      "15. Katherine Vissering Oppenheimer (née Puening; August 8, 1910 – October 27, 1972) was a German American biologist, botanist, and a member of the Communist Party of America.\n",
      "\n",
      "16. J. Robert Oppenheimer  (born Julius Robert Oppenheimer;  OP-ən-hy-mər; April 22, 1904 – February 18, 1967) was an American theoretical physicist.\n"
     ]
    }
   ],
   "source": [
    "snippet = trim(\n",
    "    list(map(lambda x: wiki.summary(x, auto_suggest=False, sentences=1), articles))\n",
    ")\n",
    "\n",
    "snippet_ = snippet.copy()\n",
    "i = 0\n",
    "for string in snippet:\n",
    "    string = f\"{i}. {string}\"\n",
    "    snippet[i] = string\n",
    "    i+=1\n",
    "snippet_text = \"\\n\\n\".join(snippet)\n",
    "print(snippet_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792e56b-df41-4a8f-9e03-d1e3a205d498",
   "metadata": {},
   "source": [
    "## Step 3. \"Brainstorm\" and filter Wikipedia searches for useful ones\n",
    "Chain-of-thought prompting\n",
    "https://www.promptingguide.ai/techniques/cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a940365-1bd4-4a4b-b6af-0aa869ab6d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. - Kenneth Sean \"Ken\" Carson Jr. is not directly related to the combined topic of Barbie and Oppenheimer, therefore not useful\n",
      "1. - Margaret \"Midge\" Hadley Sherwood is a character in the Barbie line, but not relevant to the combined topic of Barbie and Oppenheimer, therefore not useful\n",
      "2. - Barbie is a fashion doll and part of the topic, but without direct relation to Oppenheimer, therefore not useful for the combined topic\n",
      "3. - Nikolaus Barbie is unrelated to the combined topic of Barbie and Oppenheimer, therefore not useful\n",
      "4. - \"Go woke, go broke\" is a political catchphrase and not related to the combined topic of Barbie and Oppenheimer, therefore not useful\n",
      "5. - The Oppenheimer security hearing is related to J. Robert Oppenheimer, but not to the combined topic with Barbie, therefore not useful\n",
      "6. - American Prometheus is a biography of J. Robert Oppenheimer, but not related to the combined topic with Barbie, therefore not useful\n",
      "7. - Frank Friedman Oppenheimer is related to J. Robert Oppenheimer but not to the combined topic with Barbie, therefore not useful\n",
      "8. - Barbie is a 2023 fantasy comedy film, which could be relevant to the combined topic of Barbie and Oppenheimer if the presentation is about cultural impact, therefore potentially useful\n",
      "9. - Barbie's feature films are part of the Barbie topic, but not directly related to Oppenheimer, therefore not useful for the combined topic\n",
      "10. - Barbenheimer is the cultural phenomenon directly related to the simultaneous release of films about Barbie and Oppenheimer, therefore useful\n",
      "11. - Rustin is a film unrelated to the combined topic of Barbie and Oppenheimer, therefore not useful\n",
      "12. - Oppenheimer is a film about J. Robert Oppenheimer and part of the Barbenheimer phenomenon, therefore useful\n",
      "13. - The People's Choice Awards is not related to the combined topic of Barbie and Oppenheimer, therefore not useful\n",
      "14. - The friends and family of Barbie are not related to the combined topic with Oppenheimer, therefore not useful\n",
      "15. - Katherine Vissering Oppenheimer is related to J. Robert Oppenheimer but not to the combined topic with Barbie, therefore not useful\n",
      "16. - J. Robert Oppenheimer is a key figure in the combined topic due to the Barbenheimer phenomenon, therefore useful\n",
      "\n",
      "```\n",
      "[8, 10, 12, 16]\n",
      "```\n",
      "[8, 10, 12, 16]\n"
     ]
    }
   ],
   "source": [
    "choose_topics = lambda user_query: client.answer_question(\n",
    "        question=f\"\"\"{user_query}\n",
    "        Referring to the list of wikipedia entries you have been provided, decide on which topics are useful for the presentation. For each entry, explain, in a few words,\\\n",
    "        whether you think an entry is useful or not and why.\n",
    "        After that, generate a code chunk. Within the code chunk is an array of integers in JSON, and these integers correspond to the topics you think are useful. \n",
    "        Please keep strictly to the format in the following example:\n",
    "        0. - Sugar irrelevant to Jesus Christ, therefore not useful\n",
    "        1. - Christianity is about the topic of Jesus Christ, thus Useful\n",
    "        2. - Protestants follow Jesus Christ, therefore useful\n",
    "        ```\n",
    "        [1, 2]\n",
    "        ```\n",
    "        \"\"\",\n",
    "        system_prompt=f\"\"\"You are an assistant whose task is to help a user in creating a presentation.\\\n",
    "        Here are a list of wikipedia entries, starting from the 0th entry, that may or may not be related to the topic at hand:\n",
    "        {snippet_text}\n",
    "        \"\"\",\n",
    "        llm='gpt-4-1106-preview' \n",
    "    )\n",
    "\n",
    "topics = try_and_parse(user_query, choose_topics, markdown=True)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e216c3-a3fa-4755-91ed-5b56256d67cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ken (doll)',\n",
       " 'Midge (Barbie)',\n",
       " 'Barbie',\n",
       " 'Klaus Barbie',\n",
       " 'Go woke, go broke',\n",
       " 'Oppenheimer security hearing',\n",
       " 'American Prometheus',\n",
       " 'Frank Oppenheimer',\n",
       " 'Barbie (film)',\n",
       " 'List of Barbie films',\n",
       " 'Barbenheimer',\n",
       " 'Rustin (film)',\n",
       " 'Oppenheimer (film)',\n",
       " \"49th People's Choice Awards\",\n",
       " \"List of Barbie's friends and family\",\n",
       " 'Katherine Oppenheimer',\n",
       " 'J. Robert Oppenheimer']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f1e8a6a-26f2-4915-821e-9ca9e01d7899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Barbie (film)',\n",
       " 'Barbenheimer',\n",
       " 'Oppenheimer (film)',\n",
       " 'J. Robert Oppenheimer']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_articles = [articles[i] for i in topics]\n",
    "chosen_snippets = [snippet_[i] for i in topics]\n",
    "chosen_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b730249-875b-4ed0-93fc-16c2d4fd163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_full_articles = list(map(lambda x: wiki.page(x, auto_suggest=False).content, chosen_articles))\n",
    "chosen_articles_images = list(map(lambda x: wiki.page(x, auto_suggest=False).images, chosen_articles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15055ab0-f43b-4f6a-849c-c6a98ad6eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# now its time to store them for RAG\n",
    "import os\n",
    "\n",
    "\n",
    "collection_id = client.create_collection(\n",
    "    name='Articles',\n",
    "    description='wikipedia articles for presentation',\n",
    ")\n",
    "\n",
    "pages = dict(zip(chosen_articles, chosen_full_articles))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c25911-fcbe-437b-8452-0c0339b72491",
   "metadata": {},
   "source": [
    "## Step 4: Store useful ideas in VectorDB (h2oai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57bdbe96-7895-41be-9566-d99c4d03f369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./articles/Barbiefilm.txt fed!\n",
      "./articles/Barbenheimer.txt fed!\n",
      "./articles/Oppenheimerfilm.txt fed!\n",
      "./articles/JRobertOppenheimer.txt fed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Job(id='780e3d78-466f-4366-a38f-f10bef99b36f', passed=1.0, failed=0.0, progress=1.0, completed=True, canceled=False, date=datetime.datetime(2024, 2, 27, 8, 16, 3, tzinfo=TzInfo(UTC)), kind=<JobKind.IngestUploadsJob: 'IngestUploadsJob'>, statuses=[JobStatus(id='8e6b14e3d9c745168a28821c795ac686', status='Indexing done.'), JobStatus(id='11b9f1688e07496ea1271685b4a62909', status='Indexing done.'), JobStatus(id='6de0bd52efd94606898ea390a1b4b809', status='Indexing done.'), JobStatus(id='32c42eee04354d87893ea1f9bf711d9f', status='Collecting done.'), JobStatus(id='1e8c47ea9f974ab5915bf20ce35f2a0c', status='Indexing done.')], errors=[], last_update_date=datetime.datetime(2024, 2, 27, 8, 17, 4, tzinfo=TzInfo(UTC)), duration='1m1s')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "to_ingest = []\n",
    "for title, content in pages.items():\n",
    "    title = re.sub('[\\W_]+', '', title)\n",
    "    name = f\"./articles/{title}.txt\"\n",
    "    f = open(name, \"w+\", encoding=\"utf-8\")\n",
    "    f.write(content)\n",
    "    f.close() # dont know why i gotta do this, i think it has to be in binary\n",
    "    f = open(name, 'rb')\n",
    "    to_ingest.append(client.upload(name, f))\n",
    "    print(f\"{name} fed!\")\n",
    "    f.close() \n",
    "\n",
    "client.ingest_uploads(collection_id, to_ingest)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68204587-8e88-4729-a520-98c429f02b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Barbie is a 2023 fantasy comedy film, directed by Greta Gerwig from a screenplay she wrote with Noah Baumbach.',\n",
       " 'Barbenheimer ( BAR-bən-hy-mər) is a cultural phenomenon which preceded and continues to surround the simultaneous theatrical release of two films, Warner Bros.',\n",
       " 'Oppenheimer is a 2023 epic biographical thriller film written, directed, and co-produced by Christopher Nolan, starring Cillian Murphy as J. Robert Oppenheimer, the American theoretical physicist credited with being the \"father of the atomic bomb\" for his role in the Manhattan Project—the World War II undertaking that developed the first nuclear weapons.',\n",
       " 'J. Robert Oppenheimer  (born Julius Robert Oppenheimer;  OP-ən-hy-mər; April 22, 1904 – February 18, 1967) was an American theoretical physicist.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d92505-2864-4532-a6d0-feb91d1d4fe4",
   "metadata": {},
   "source": [
    "## Step 5: Plan sections for slide\n",
    "This is to ensure the entire presentation is a coherent one with a flow/narrative, instead of many disjoint/overlapping generations.\n",
    "Again, chain of thought prompting is very heavily incorporated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d1a7ba5-2cdf-4f4e-b811-2d17abf3f119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. I would design the presentation slides as follows:\n",
      "* Slide 1: Title slide with the title \"Barbenheimer: A Tale of Two Movies\"\n",
      "* Slide 2: Introduction to Barbie (2023) - provide a brief summary of the film, its genre, and director\n",
      "* Slide 3: Introduction to Oppenheimer (2023) - provide a brief summary of the film, its genre, and director\n",
      "* Slide 4: Comparing Barbie and Oppenheimer - discuss the similarities and differences between the two films, such as their release dates, genres, and directors\n",
      "* Slide 5: The Cultural Phenomenon of Barbenheimer - discuss the cultural significance of the simultaneous release of the two films and how they have been received by audiences\n",
      "* Slide 6: J. Robert Oppenheimer - provide a brief biography of the historical figure and his role in the development of the atomic bomb\n",
      "* Slide 7: The Manhattan Project - discuss the World War II undertaking that developed the first nuclear weapons and Oppenheimer's role in it\n",
      "* Slide 8: The Legacy of Oppenheimer - discuss the impact of Oppenheimer's work on modern society and the ethical considerations surrounding the development of nuclear weapons\n",
      "* Slide 9: Conclusion - summarize the key points of the presentation and provide closing remarks\n",
      "2. I think a good title for this presentation is \"Barbenheimer: A Tale of Two Movies\", because it highlights the cultural phenomenon surrounding the simultaneous release of the two films and sets the tone for the rest of the presentation.\n",
      "3. Here is the JSON array of slide titles:\n",
      "```json\n",
      "[\"Barbenheimer: A Tale of Two Movies\", \"Introduction to Barbie (2023)\", \"Introduction to Oppenheimer (2023)\", \"Comparing Barbie and Oppenheimer\", \"The Cultural Phenomenon of Barbenheimer\", \"J. Robert Oppenheimer\", \"The Manhattan Project\", \"The Legacy of Oppenheimer\", \"Conclusion\"]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "decide_sections = lambda user_query: client.answer_question(\n",
    "        question=f\"\"\"{user_query}\n",
    "        Please plan the presentation by doing the following:\n",
    "        1. Explain how you would design the presentation slides such that the presentation will flow well.\\\n",
    "        Remember that each slide must contain something different, and content should not overlap.\n",
    "        2. Think of a good title for the presentation.\n",
    "        3. Create a code chunk. Inside that code chunk, generate a JSON array consisting of appropriate slide titles starting from the first slide to the last slide, \\\n",
    "        remembering your answer to point 2. Include the title slide, which is the title for the presentation.\n",
    "\n",
    "        Below is an example reply. Please adhere strictly to the format in the example below:  \n",
    "        1. I would introduce the subject of cookies and provide general information about its history to ease my viewers into the subject. \\\n",
    "        Then, I will discuss more specific topics, such as...\n",
    "        2. I think a good title for this presentation is \"xxx\", because...\n",
    "        3. Here is the json array of slide titles:\n",
    "        ```json\n",
    "        [\"xxx\", \"Introduction to Cookies\", \"History of cookies\",\\\n",
    "        \"Sourdough Cookies\", \"Chocolate Cookies\", \"Health Concerns\", \"Conclusion\"]\n",
    "        ```\n",
    "        \"\"\",\n",
    "        system_prompt=f\"\"\"You are an assistant whose task is to help a user in creating a presentation.\\\n",
    "        Here are a list of wikipedia entry summaries that are selected for the presentation:\n",
    "        {chosen_snippets}\n",
    "        You will be asked to come up with slide titles for the presentation.\n",
    "        \"\"\",\n",
    "        llm='mistralai/Mixtral-8x7B-Instruct-v0.1' \n",
    "    )\n",
    "\n",
    "all_sections = try_and_parse(user_query, decide_sections, markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74ac776f-de82-461d-9313-e671d1ae2dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Introduction to Barbie (2023)',\n",
       " 'Introduction to Oppenheimer (2023)',\n",
       " 'Comparing Barbie and Oppenheimer',\n",
       " 'The Cultural Phenomenon of Barbenheimer',\n",
       " 'J. Robert Oppenheimer',\n",
       " 'The Manhattan Project',\n",
       " 'The Legacy of Oppenheimer',\n",
       " 'Conclusion']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections = all_sections[1:]\n",
    "\n",
    "sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5e83322-475c-4678-8f4c-f822ab5e5386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a49aeb95-c48f-4cbf-8ee1-2962ccd3cee2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del client\n",
    "client = H2OGPTE(\n",
    "    address=\"https://h2ogpte.genai.h2o.ai\",\n",
    "    api_key=api\n",
    ") # does this reset client?\n",
    "\n",
    "chat_session_id = client.create_chat_session(collection_id)\n",
    "chat_session_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e579f-ced4-4c01-93b8-4237e0872788",
   "metadata": {},
   "source": [
    "#### Ref for slide types:  \n",
    "0. title and subtitle \n",
    "1. title and content \n",
    "2. section header \n",
    "3. two content \n",
    "4. Comparison \n",
    "5. Title only  \n",
    "6. Blank \n",
    "7. Content with caption \n",
    "8. Pic with caption \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17338590-9279-49a6-8674-17f2b8c57cdd",
   "metadata": {},
   "source": [
    "## Step 6: Generate using RAG\n",
    "LLM chooses colour with chain-of-thought prompting again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11c297ad-f4ef-4aac-a719-e8f2c8237a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have chosen a light purple color with RGB values of [175, 152, 255] for the background and a dark blue color with RGB values of [0, 0, 100] for the text. The contrast between the light purple background and the dark blue text will make it easy to read the text on the slides. Additionally, the color purple is often associated with creativity and imagination, which aligns well with the theme of the Barbie movie, while the color blue is associated with intelligence and trust, which is fitting for the Oppenheimer portion of the presentation.\n",
      "\n",
      "Here is the JSON array containing the background and text colors:\n",
      "```\n",
      "[{\"background\": [175, 152, 255]}, {\"text\": [0, 0, 100]}]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prs = Presentation()\n",
    "prs.slide_width = Inches(16)\n",
    "prs.slide_height = Inches(9)\n",
    "title_slide = prs.slides.add_slide(prs.slide_layouts[0]) \n",
    "decide_slide_format = lambda user_query: client.answer_question(\n",
    "        question=f\"\"\"{user_query} Think of a good background colour, in RGB format,\\\n",
    "        for the slides and a good colour, also in RGB format, for the\\\n",
    "        text. Typically, if the text colour is bright (for example RGB [255, 255, 255] is white), then the background colour should be dark\n",
    "        (RGB [0, 0, 100] is dark blue). Conversely, if the text colour is dark (for example RGB [0, 0, 0] is black), the background colour should be bright\\\n",
    "        . You are free to choose any text and background colour, \\\n",
    "        as long as you follow these rules. Please do not assign grey-scale colours for the text and background (like RGB [50, 50, 50]), as much as possible.\n",
    "\n",
    "        Explain clearly why you chose the background and text colours. Then, generate a code chunk. Within the code chunk,\\\n",
    "        provide a JSON array containing two colours. Adhere strictly to the example reply below:\n",
    "        I chose blue RGB [0, 35, 140] for the background color and light yellow RGB [255, 234, 0] for the font color. The contrast makes it easy to read.\\\n",
    "        Furthermore, the colours blue and yellow are associated with the Pokémon Franchise.\n",
    "        ```\n",
    "        [{{\"background\": [0, 0, 140]}}, {{\"text\": [255, 234, 0]}}]\n",
    "        ```\n",
    "        \"\"\",\n",
    "    \n",
    "        system_prompt=f\"\"\"You are an assistant whose task is to help a user in creating a presentation.\\\n",
    "        Here are a list of wikipedia entry summaries that are selected for the presentation:\n",
    "        {chosen_snippets}\n",
    "        This should give you an idea of what this presentation should be about.\n",
    "        \"\"\",\n",
    "        llm='mistralai/Mixtral-8x7B-Instruct-v0.1' \n",
    ")\n",
    "\n",
    "format = try_and_parse(user_query, decide_slide_format, markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a40b715-2ef3-47f0-bcab-db6733e54873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'background': [175, 152, 255]}, {'text': [0, 0, 100]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75e78e2a-08ef-4fed-8833-a6ad0296110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = RGBColor(*tuple(list(format[0].values())[0])) \n",
    "font = RGBColor(*tuple(list(format[1].values())[0])) \n",
    "fill = title_slide.background.fill\n",
    "fill.solid()\n",
    "fill.fore_color.rgb = background\n",
    "\n",
    "\n",
    "title_slide.shapes.title.text = all_sections[0]\n",
    "title_slide.shapes.title.text_frame.paragraphs[0].font.color.rgb =  font\n",
    "title_slide.shapes.title.text_frame.paragraphs[0].font.name = 'Montserrat'\n",
    "title_slide.shapes.title.text_frame.paragraphs[0].font.bold = True\n",
    "\n",
    "first_shape =  title_slide.shapes[0]\n",
    "first_shape.left, first_shape.top, first_shape.width, first_shape.height = (prs.slide_width - Inches(12))//2, \\\n",
    "(prs.slide_height-first_shape.height)//2 - Inches(1),\\\n",
    "Inches(12),\\\n",
    "Inches(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14ebca46-abd0-45a9-9f13-82c9242dc2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [12:21<00:00, 92.66s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with client.connect(chat_session_id) as session:\n",
    "\n",
    "    for section in tqdm(sections):\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "        fill = slide.background.fill\n",
    "        fill.solid()\n",
    "        fill.fore_color.rgb = background\n",
    "\n",
    "        \n",
    "        contents = slide.placeholders[1]\n",
    "        contents.text_frame.word_wrap = True\n",
    "\n",
    "        title = slide.shapes.title\n",
    "        title.text = section\n",
    "        title.text_frame.paragraphs[0].font.color.rgb = font\n",
    "        title.text_frame.paragraphs[0].font.size = Pt(32)\n",
    "        title.text_frame.paragraphs[0].font.name = 'Karla'\n",
    "       \n",
    "       \n",
    "        content = session.query(\n",
    "            \n",
    "            message = section,\n",
    "            system_prompt=f\"\"\"You are an assistant whose task is to help a user in creating a presentation. \\\n",
    "            The slides of the presentation are as follows: {sections}\n",
    "            You are now tasked with generating the content of one slide, which will be provided by the user.\n",
    "            \"\"\",\n",
    "            pre_prompt_query=\"You have been provided with the following information, which may be useful in your task.\",\n",
    "            prompt_query=\"Decide if the information is relevant, and use it if needed. \\\n",
    "            Generate the content required in the slide provided by the user. You only need to generate the contents of the slide, not the title\\\n",
    "            or anything else. Generate a maximum of 3 paragraphs of text. Keep to a word limit of 250 words. \\\n",
    "            Do not use numbered lists.\",\n",
    "            llm=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "            rag_config={\n",
    "                \"rag_type\": \"rag\",\n",
    "            },\n",
    "        ).content\n",
    "\n",
    "        contents.text = content\n",
    "        \n",
    "        for paragraph in contents.text_frame.paragraphs:\n",
    "            paragraph.space_after = 1\n",
    "            paragraph.space_before = 0\n",
    "           \n",
    "            paragraph.font.size = Pt(18)  \n",
    "            paragraph.font.color.rgb = font\n",
    "            paragraph.font.name = 'Karla'\n",
    "\n",
    "        contents.text_frame.auto_size = MSO_AUTO_SIZE.SHAPE_TO_FIT_TEXT\n",
    "        shapes = slide.shapes\n",
    "        new_width = Inches(14)\n",
    "        new_height = Inches(7)\n",
    "        shapes[0].height, shapes[0].width, shapes[0].top, shapes[0].left = shapes[0].height, new_width, shapes[0].top, (prs.slide_width-new_width)//2\n",
    "        shapes[1].height, shapes[1].width, shapes[1].top, shapes[1].left = new_height, new_width, shapes[1].top, (prs.slide_width-new_width)//2\n",
    "        \n",
    "        \n",
    "\n",
    "# gpt-4-1106-preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5355475-527a-47b4-81ec-aff43b9f8142",
   "metadata": {},
   "source": [
    "## Step 7: Enjoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3de66b9-768e-48c5-9e7d-2b7c5411d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitised = re.sub(r'[\\W_]+', '_', all_sections[0])\n",
    "prs.save(f\"./presentations/{sanitised}.pptx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9df9ce-fdad-4bb9-9707-0051dc9ab84c",
   "metadata": {},
   "source": [
    "## Appendix: Extra Code that may be useful in the future\n",
    "```python\n",
    "# Create a chat session\n",
    "# chat_session_id = client.create_chat_session(collection_id)\n",
    "\n",
    "# # Query the collection\n",
    "# with client.connect(chat_session_id) as session:\n",
    "#     reply = session.query(\n",
    "#         'How many paper clips were shipped to Scranton?',\n",
    "#         llm=\"gpt-4-0613\"\n",
    "#     )\n",
    "#     print(reply.content)\n",
    "\n",
    "#     reply = session.query(\n",
    "#         'Did David Brent co-sign the contract with Initech?',\n",
    "#         timeout=60,\n",
    "#         llm=\"gpt-4-0613\"\n",
    "#     )\n",
    "#     print(reply.content)\n",
    "\n",
    "# # Summarize each document\n",
    "# documents = client.list_documents_in_collection(collection_id, offset=0, limit=99)\n",
    "# for doc in documents:\n",
    "#     summary = client.summarize_document(\n",
    "#         document_id=doc.id,\n",
    "#         timeout=60,\n",
    "#     )\n",
    "#     print(summary.content)\n",
    "\n",
    "\n",
    "#client.delete_documents_from_collection\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
